{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356861\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 249472 entries, 2805 to 26023521\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   UserID     249472 non-null  int64         \n",
      " 1   MovieID    249472 non-null  int64         \n",
      " 2   Rating     249472 non-null  float64       \n",
      " 3   Timestamp  249472 non-null  datetime64[ns]\n",
      " 4   movieID    249472 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 11.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "data_df = pd.read_csv('./ratings.csv', sep=',', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"],dtype={'Rating':'float64'})\n",
    " #dtype={'UserID':'int64','MovieID':'int64','Rating':'float64','Timestamp':'float'}\n",
    "#dataframe object with movie information\n",
    "#movie_data_df = pd.read_csv('./movies_metadata.csv', sep=',', names=[\"movieId\", \"title\", \"genres\"])\n",
    "\n",
    "#data_df['Timestamp'] = pd.to_datetime(data_df['Timestamp'])\n",
    "data_df['Timestamp'] = pd.to_datetime(data_df['Timestamp'], unit='s')\n",
    "cutoff_date = \"2017-06-01\" # this was the earliest i could do without a memory error\n",
    "data_df = data_df[data_df['Timestamp'] >= cutoff_date]\n",
    "                    \n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "user_list = data_df['UserID'].values\n",
    "movie_list = data_df['MovieID'].values\n",
    "for j in range(len(data_df)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
    "data_df['UserID'] = user_list\n",
    "data_df['movieID'] = movie_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "train_index = np.random.random(len(data_df)) <= 0.7\n",
    "train_df = data_df[train_index]\n",
    "test_df = data_df[~train_index]\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "num_ratings = len(data_df['Rating'])\n",
    "print(num_ratings)\n",
    "\n",
    "print(train_df.info())\n",
    "# train_mat = train_df[['Rating', 'UserID']].copy()\n",
    "# test_mat = test_df[['Rating', 'UserID']].copy()\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "train_mat = (train_mat > 0).astype(float)\n",
    "test_mat = (test_mat > 0).astype(float)\n",
    "\n",
    "print(train_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-user Collaborative Filtering with implicit feedback (from hw2) SWITCH TO ITEM-ITEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.13129103 0.08258929 ... 0.         0.         0.        ]\n",
      " [0.13129103 1.         0.09465021 ... 0.         0.         0.        ]\n",
      " [0.08258929 0.09465021 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         1.         1.        ]\n",
      " [0.         0.         0.         ... 1.         1.         1.        ]\n",
      " [0.         0.         0.         ... 1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#implicit user user collab filtering\n",
    "\n",
    "# numer = np.matmul(train_mat, train_mat.T)\n",
    "# denom = np.sum(train_mat ** 2, axis=1, keepdims=True) ** 0.5\n",
    "# Cosine = numer / np.matmul(denom, denom.T)\n",
    "\n",
    "# calculating cosinne similarity between items\n",
    "num_rating_items = np.sum(train_mat, axis=0, keepdims=True)\n",
    "numer = np.matmul(train_mat.T, train_mat)  # num_item * num_item\n",
    "denom = num_rating_items.T + num_rating_items - numer  # num_item * num_item\n",
    "denom[denom == 0] = 1\n",
    "cosine_sim_mat = numer / denom  # num_item * num_item\n",
    "print(cosine_sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40739744 0.43044576 0.40008909 ... 0.         0.         0.        ]\n",
      "[17711 13992 14343   393   178    23   330   501   145    71   351    37\n",
      "    66    34   187   159   184   156   269   127     7   551   790   461\n",
      "   439  1106   311   173   907    70   472   179   144  2209   241   506\n",
      "   835   541   441   227    40   727    48  2132   225   546   962    52\n",
      "    80   181]\n"
     ]
    }
   ],
   "source": [
    "#use cosine sim mat to give recommendations\n",
    "\n",
    "#track which items the user likes so we can find similar items\n",
    "user_train_like = []\n",
    "for u in range(num_user):\n",
    "    user_train_like.append(np.where(train_mat[u,:] > 0)[0])\n",
    "\n",
    "\n",
    "prediction_mat = train_mat.copy()\n",
    "for i in range(num_movie):\n",
    "    similarities = cosine_sim_mat[i, :]\n",
    "    similarities[i] = -1\n",
    "    N_idx = np.argpartition(similarities, -10)[-10:]\n",
    "    N_sim = similarities[N_idx]\n",
    "    prediction_mat[:, i] = np.sum(N_sim.reshape((1, -1)) * train_mat[:, N_idx], axis=1) / (np.sum(N_sim) + 1e-10)\n",
    "    \n",
    "print(prediction_mat[0])\n",
    "\n",
    "recommendation = []\n",
    "for u in range(num_user):\n",
    "    train_like = user_train_like[u]\n",
    "    prediction_mat[u][train_like] = -9999\n",
    "    top50_iid = np.argpartition(prediction_mat[u], -50)[-50:]\n",
    "    top50_iid = top50_iid[np.argsort(prediction_mat[u][top50_iid])[-1::-1]]\n",
    "    recommendation.append(top50_iid)\n",
    "    \n",
    "print(recommendation[0])\n",
    "# recommendation = []\n",
    "# for i in range(num_movie):\n",
    "#     similarities = cosine_sim_mat[i, :]\n",
    "#     similarities[i] = -1\n",
    "#     N_idx = np.argpartition(similarities, -10)[-10:]\n",
    "#     N_sim = similarities[N_idx]\n",
    "#     scores = np.sum(N_sim.reshape((1, -1)) * train_mat[:, N_idx], axis=0) / np.sum(N_sim)\n",
    "    \n",
    "#     train_like = item_train_like[i]\n",
    "#     scores[train_like] = -9999\n",
    "#     top50_iid = np.argpartition(scores, -50)[-50:]\n",
    "#     top50_iid = top50_iid[np.argsort(scores[top50_iid])[-1::-1]]\n",
    "#     recommendation.append(top50_iid)\n",
    "# recommendation = np.array(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f5188342f5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_like_num\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecommendation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# Calculate recall@k, precision@k with k=5, 20, 50 and print out the average over all users for these 6 metrics.\n",
    "# Your Code Here...\n",
    "\n",
    "user_test_like = []\n",
    "for u in range(num_user):\n",
    "    user_test_like.append(np.where(test_mat[u, :] > 0)[0])\n",
    "    \n",
    "recalls = np.zeros(3)\n",
    "precisions = np.zeros(3)\n",
    "user_count = 0.\n",
    "\n",
    "for u in range(num_user):\n",
    "    test_like = user_test_like[u]\n",
    "    test_like_num = len(test_like)\n",
    "    if test_like_num == 0:\n",
    "        continue\n",
    "    rec = recommendation[u, :]\n",
    "    hits = np.zeros(3)\n",
    "    for k in range(50):\n",
    "        if rec[k] in test_like:\n",
    "            if k < 50:\n",
    "                hits[2] += 1\n",
    "                if k < 20:\n",
    "                    hits[1] += 1\n",
    "                    if k < 5:\n",
    "                        hits[0] += 1\n",
    "    recalls[0] += (hits[0] / test_like_num)\n",
    "    recalls[1] += (hits[1] / test_like_num)\n",
    "    recalls[2] += (hits[2] / test_like_num)\n",
    "    precisions[0] += (hits[0] / 5.)\n",
    "    precisions[1] += (hits[1] / 20.)\n",
    "    precisions[2] += (hits[2] / 50.)\n",
    "    user_count += 1\n",
    "\n",
    "recalls /= user_count\n",
    "precisions /= user_count\n",
    "\n",
    "print('recall@5\\t[%.6f],\\t||\\t recall@20\\t[%.6f],\\t||\\t recall@50\\t[%.6f]' % (recalls[0], recalls[1], recalls[2]))\n",
    "print('precision@5\\t[%.6f],\\t||\\t precision@20\\t[%.6f],\\t||\\t precision@50\\t[%.6f]' % (precisions[0], precisions[1], precisions[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
